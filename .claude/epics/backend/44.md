---
name: 音频处理系统
status: backlog
created: 2025-09-15T02:51:00Z
github: https://github.com/rcnn/sharestack/issues/44
depends_on: [001, 41]
parallel: true
conflicts_with: []
---

# Task: 音频处理系统

## Description

实现完整的音频处理系统，包括音频格式转换、质量压缩、元数据提取、波形生成、音频剪辑等功能。支持多种音频格式和高质量音频处理。

## Acceptance Criteria

- [ ] 完成音频转换API (/api/v1/media/audios/convert)
- [ ] 完成音频元数据API (/api/v1/media/audios/metadata)
- [ ] 实现音频质量优化功能
- [ ] 实现音频波形生成
- [ ] 实现音频格式转换
- [ ] 实现音频剪辑和编辑
- [ ] 实现批量音频处理
- [ ] 编写完整的测试用例

## Technical Details

### 音频处理引擎

#### 使用FFmpeg和librosa进行音频处理
```python
import subprocess
import json
import librosa
import numpy as np
import matplotlib.pyplot as plt
from pydub import AudioSegment

class AudioProcessor:
    SUPPORTED_FORMATS = ['mp3', 'wav', 'flac', 'aac', 'ogg', 'wma', 'm4a']
    OUTPUT_FORMATS = ['mp3', 'wav', 'flac', 'aac', 'ogg']

    def __init__(self):
        self.ffmpeg_path = self._find_ffmpeg()

    def convert_format(self, input_path, output_path, target_format='mp3', quality='medium'):
        """音频格式转换"""
        quality_settings = {
            'low': {'bitrate': '128k', 'sample_rate': '44100'},
            'medium': {'bitrate': '192k', 'sample_rate': '44100'},
            'high': {'bitrate': '320k', 'sample_rate': '48000'},
            'lossless': {'bitrate': None, 'sample_rate': '48000'}
        }

        settings = quality_settings.get(quality, quality_settings['medium'])

        cmd = [
            self.ffmpeg_path,
            '-i', input_path,
            '-acodec', self._get_codec_for_format(target_format),
            '-ar', settings['sample_rate'],
        ]

        if settings['bitrate'] and target_format != 'flac':
            cmd.extend(['-ab', settings['bitrate']])

        cmd.extend(['-y', output_path])

        return self._run_ffmpeg_command(cmd)

    def extract_metadata(self, audio_path):
        """提取音频元数据"""
        cmd = [
            self.ffmpeg_path.replace('ffmpeg', 'ffprobe'),
            '-v', 'quiet',
            '-print_format', 'json',
            '-show_format',
            '-show_streams',
            audio_path
        ]

        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            metadata = json.loads(result.stdout)

            # 解析音频流信息
            audio_stream = None
            for stream in metadata.get('streams', []):
                if stream.get('codec_type') == 'audio':
                    audio_stream = stream
                    break

            if not audio_stream:
                return None

            format_info = metadata.get('format', {})

            return {
                'duration': float(format_info.get('duration', 0)),
                'size': int(format_info.get('size', 0)),
                'bitrate': format_info.get('bit_rate'),
                'format': format_info.get('format_name'),
                'codec': audio_stream.get('codec_name'),
                'sample_rate': int(audio_stream.get('sample_rate', 0)),
                'channels': int(audio_stream.get('channels', 0)),
                'channel_layout': audio_stream.get('channel_layout'),
                'raw_metadata': metadata
            }

        except subprocess.CalledProcessError as e:
            logger.error(f"提取音频元数据失败: {e}")
            return None

    def generate_waveform(self, audio_path, output_path, width=1200, height=300):
        """生成音频波形图"""
        try:
            # 使用librosa加载音频
            y, sr = librosa.load(audio_path, sr=None)

            # 创建波形图
            plt.figure(figsize=(width/100, height/100), dpi=100)
            plt.plot(np.linspace(0, len(y)/sr, len(y)), y, color='#1f77b4', linewidth=0.5)
            plt.xlim(0, len(y)/sr)
            plt.ylim(-1, 1)
            plt.axis('off')
            plt.tight_layout(pad=0)

            # 保存波形图
            plt.savefig(output_path, bbox_inches='tight', pad_inches=0,
                       facecolor='white', edgecolor='none')
            plt.close()

            return True

        except Exception as e:
            logger.error(f"生成音频波形失败: {str(e)}")
            return False

    def generate_spectrogram(self, audio_path, output_path):
        """生成音频频谱图"""
        try:
            y, sr = librosa.load(audio_path)

            # 计算短时傅里叶变换
            D = librosa.stft(y)
            S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)

            # 创建频谱图
            plt.figure(figsize=(12, 6))
            librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='hz')
            plt.colorbar(format='%+2.0f dB')
            plt.title('Spectrogram')
            plt.tight_layout()

            # 保存频谱图
            plt.savefig(output_path, dpi=150, bbox_inches='tight')
            plt.close()

            return True

        except Exception as e:
            logger.error(f"生成频谱图失败: {str(e)}")
            return False

    def normalize_audio(self, input_path, output_path, target_db=-20.0):
        """音频标准化"""
        try:
            audio = AudioSegment.from_file(input_path)

            # 计算当前音量
            current_db = audio.dBFS

            # 计算需要调整的分贝数
            change_db = target_db - current_db

            # 应用音量调整
            normalized_audio = audio + change_db

            # 导出标准化后的音频
            normalized_audio.export(output_path, format=self._get_format_from_path(output_path))

            return True

        except Exception as e:
            logger.error(f"音频标准化失败: {str(e)}")
            return False

    def trim_audio(self, input_path, output_path, start_time, end_time):
        """音频剪辑"""
        try:
            audio = AudioSegment.from_file(input_path)

            # 转换时间为毫秒
            start_ms = int(start_time * 1000)
            end_ms = int(end_time * 1000)

            # 剪辑音频
            trimmed_audio = audio[start_ms:end_ms]

            # 导出剪辑后的音频
            trimmed_audio.export(output_path, format=self._get_format_from_path(output_path))

            return True

        except Exception as e:
            logger.error(f"音频剪辑失败: {str(e)}")
            return False

    def fade_in_out(self, input_path, output_path, fade_in_duration=1.0, fade_out_duration=1.0):
        """添加淡入淡出效果"""
        try:
            audio = AudioSegment.from_file(input_path)

            # 添加淡入淡出
            fade_in_ms = int(fade_in_duration * 1000)
            fade_out_ms = int(fade_out_duration * 1000)

            faded_audio = audio.fade_in(fade_in_ms).fade_out(fade_out_ms)

            # 导出处理后的音频
            faded_audio.export(output_path, format=self._get_format_from_path(output_path))

            return True

        except Exception as e:
            logger.error(f"添加淡入淡出失败: {str(e)}")
            return False

    def merge_audios(self, audio_paths, output_path, crossfade_duration=0.5):
        """合并多个音频文件"""
        try:
            if not audio_paths:
                return False

            # 加载第一个音频
            combined = AudioSegment.from_file(audio_paths[0])

            # 逐个合并其他音频
            crossfade_ms = int(crossfade_duration * 1000)

            for audio_path in audio_paths[1:]:
                next_audio = AudioSegment.from_file(audio_path)
                combined = combined.append(next_audio, crossfade=crossfade_ms)

            # 导出合并后的音频
            combined.export(output_path, format=self._get_format_from_path(output_path))

            return True

        except Exception as e:
            logger.error(f"音频合并失败: {str(e)}")
            return False

    def _get_codec_for_format(self, format):
        """获取格式对应的编码器"""
        codecs = {
            'mp3': 'libmp3lame',
            'aac': 'aac',
            'ogg': 'libvorbis',
            'flac': 'flac',
            'wav': 'pcm_s16le'
        }
        return codecs.get(format, 'libmp3lame')

    def _get_format_from_path(self, path):
        """从文件路径获取格式"""
        return os.path.splitext(path)[1][1:].lower()

    def _run_ffmpeg_command(self, cmd):
        """执行FFmpeg命令"""
        try:
            subprocess.run(cmd, capture_output=True, text=True, check=True)
            return True
        except subprocess.CalledProcessError as e:
            logger.error(f"FFmpeg命令执行失败: {e.stderr}")
            return False

    def _find_ffmpeg(self):
        """查找FFmpeg可执行文件"""
        import shutil
        ffmpeg_path = shutil.which('ffmpeg')
        if not ffmpeg_path:
            raise RuntimeError("未找到FFmpeg，请确保已正确安装")
        return ffmpeg_path
```

### API接口实现

#### 音频处理接口
- **POST /api/v1/media/audios/convert**
  - 请求参数:
    - file_id: 文件ID
    - target_format: 目标格式 (mp3, wav, flac等)
    - quality: 质量等级 (low, medium, high, lossless)
  - 响应: 202 Accepted + 任务ID

- **GET /api/v1/media/audios/{id}/metadata**
  - 获取音频元数据信息
  - 响应: 200 OK + 元数据详情

- **POST /api/v1/media/audios/waveform**
  - 请求参数:
    - file_id: 文件ID
    - width: 波形图宽度 (默认1200)
    - height: 波形图高度 (默认300)
  - 响应: 201 Created + 波形图信息

### 异步音频处理

```python
@celery.task(bind=True)
def process_audio_task(self, file_id, operation, params, user_id):
    """异步音频处理任务"""
    try:
        self.update_state(state='PROGRESS', meta={'progress': 0, 'status': '开始处理'})

        file_record = MediaFileRepository.get_by_id(file_id)
        if not file_record:
            raise ValueError("文件不存在")

        processor = AudioProcessor()

        if operation == 'convert':
            # 音频格式转换
            output_path = generate_audio_output_path(
                file_record.filename,
                params.get('target_format', 'mp3')
            )

            self.update_state(state='PROGRESS', meta={'progress': 30, 'status': '转换中'})

            success = processor.convert_format(
                file_record.file_path,
                output_path,
                target_format=params.get('target_format', 'mp3'),
                quality=params.get('quality', 'medium')
            )

            if success:
                new_file_record = MediaFileService.create_processed_file(
                    output_path, file_record, user_id
                )

                self.update_state(state='SUCCESS', meta={
                    'progress': 100,
                    'status': '转换完成',
                    'file_id': new_file_record.id
                })

                return {'status': 'success', 'file_id': new_file_record.id}

        elif operation == 'waveform':
            # 生成波形图
            output_path = generate_waveform_path(file_record.filename)

            self.update_state(state='PROGRESS', meta={'progress': 50, 'status': '生成波形图'})

            success = processor.generate_waveform(
                file_record.file_path,
                output_path,
                width=params.get('width', 1200),
                height=params.get('height', 300)
            )

            if success:
                waveform_record = MediaFileService.create_waveform_record(
                    output_path, file_record, user_id
                )

                self.update_state(state='SUCCESS', meta={
                    'progress': 100,
                    'status': '波形图生成完成',
                    'waveform_id': waveform_record.id
                })

                return {'status': 'success', 'waveform_id': waveform_record.id}

        elif operation == 'normalize':
            # 音频标准化
            output_path = generate_normalized_path(file_record.filename)

            self.update_state(state='PROGRESS', meta={'progress': 40, 'status': '标准化处理'})

            success = processor.normalize_audio(
                file_record.file_path,
                output_path,
                target_db=params.get('target_db', -20.0)
            )

            if success:
                normalized_record = MediaFileService.create_processed_file(
                    output_path, file_record, user_id
                )

                self.update_state(state='SUCCESS', meta={
                    'progress': 100,
                    'status': '标准化完成',
                    'file_id': normalized_record.id
                })

                return {'status': 'success', 'file_id': normalized_record.id}

    except Exception as e:
        logger.error(f"音频处理任务失败: {str(e)}")
        self.update_state(state='FAILURE', meta={'error': str(e)})
        raise
```

### 音频分析功能

```python
class AudioAnalyzer:
    def analyze_audio_features(self, audio_path):
        """分析音频特征"""
        try:
            y, sr = librosa.load(audio_path)

            # 基本特征
            duration = len(y) / sr
            tempo, beats = librosa.beat.beat_track(y=y, sr=sr)

            # 频谱特征
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
            zero_crossing_rate = librosa.feature.zero_crossing_rate(y)[0]

            # MFCC特征
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

            # 色度特征
            chroma = librosa.feature.chroma_stft(y=y, sr=sr)

            return {
                'duration': duration,
                'tempo': float(tempo),
                'spectral_centroid_mean': float(np.mean(spectral_centroids)),
                'spectral_rolloff_mean': float(np.mean(spectral_rolloff)),
                'zero_crossing_rate_mean': float(np.mean(zero_crossing_rate)),
                'mfcc_mean': np.mean(mfccs, axis=1).tolist(),
                'chroma_mean': np.mean(chroma, axis=1).tolist()
            }

        except Exception as e:
            logger.error(f"音频特征分析失败: {str(e)}")
            return None

    def detect_silence(self, audio_path, silence_threshold=-40.0, min_silence_len=1000):
        """检测音频中的静音片段"""
        try:
            audio = AudioSegment.from_file(audio_path)

            # 检测静音片段
            silence_ranges = []
            audio_length = len(audio)

            # 以100ms为单位检测
            chunk_size = 100
            for i in range(0, audio_length, chunk_size):
                chunk = audio[i:i+chunk_size]
                if chunk.dBFS < silence_threshold:
                    silence_ranges.append((i, min(i+chunk_size, audio_length)))

            # 合并连续的静音片段
            merged_ranges = []
            if silence_ranges:
                current_start, current_end = silence_ranges[0]
                for start, end in silence_ranges[1:]:
                    if start <= current_end + chunk_size:
                        current_end = end
                    else:
                        if current_end - current_start >= min_silence_len:
                            merged_ranges.append((current_start, current_end))
                        current_start, current_end = start, end

                if current_end - current_start >= min_silence_len:
                    merged_ranges.append((current_start, current_end))

            return merged_ranges

        except Exception as e:
            logger.error(f"静音检测失败: {str(e)}")
            return []
```

## Dependencies

- [ ] Task 001: 后端基础架构
- [ ] Task 020: 文件上传系统
- [ ] FFmpeg音频处理工具
- [ ] librosa音频分析库
- [ ] pydub音频处理库
- [ ] Celery异步任务处理

## Effort Estimate

- Size: L
- Hours: 22小时
- Parallel: true

## Definition of Done

- [ ] 所有音频处理API接口实现完成
- [ ] 音频格式转换功能正常
- [ ] 音频元数据提取准确
- [ ] 波形图生成功能正常
- [ ] 音频编辑功能完整
- [ ] 音频分析功能正确
- [ ] 异步处理稳定可靠
- [ ] 单元测试覆盖率达到90%
- [ ] API文档更新完成

## Implementation Notes

### Service层设计
```python
class AudioProcessingService:
    def convert_audio(self, file_id, params, user_id):
        """启动音频转换任务"""
        pass

    def generate_waveform(self, file_id, params, user_id):
        """生成音频波形图"""
        pass

    def analyze_audio(self, file_id, user_id):
        """分析音频特征"""
        pass

    def edit_audio(self, file_id, edit_params, user_id):
        """编辑音频"""
        pass
```

### 缓存策略
- `audio:metadata:{id}`: 音频元数据缓存 (TTL: 24小时)
- `audio:waveform:{id}`: 波形图缓存 (TTL: 7天)
- `audio:features:{id}`: 音频特征缓存 (TTL: 30天)

### 错误处理
- 415: 不支持的音频格式
- 422: 音频参数无效
- 500: 音频处理失败
- 413: 音频文件过大